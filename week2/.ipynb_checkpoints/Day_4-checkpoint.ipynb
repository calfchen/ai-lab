{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今天尝试一下其他的算法模型\n",
    "\n",
    "- 注：前几天做为了用 snap 都是用 python2 做的，现在用换回到 python3 环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入常用库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "from copy import deepcopy \n",
    "from tqdm import tqdm\n",
    "% matplotlib inline\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 随机游走算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "path = './ml-100k/'\n",
    "# 读入数据\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df_train = pd.read_csv(path+'u1.base', sep='\\t', names=names)\n",
    "df_test = pd.read_csv(path+'u1.test', sep='\\t', names=names)\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data['u_user_id'] = data['user_id'].map(lambda x: 'u'+str(x))\n",
    "    data['i_item_id'] = data['item_id'].map(lambda x: 'i'+str(x))\n",
    "    data['edges'] = data.apply(lambda x: (x['u_user_id'], x['i_item_id']), axis = 1)\n",
    "    # 获得 user 节点，以及 item 节点\n",
    "    user_ids = data.u_user_id.unique().tolist()\n",
    "    item_ids = data.i_item_id.unique().tolist()\n",
    "    edges = data.edges.unique().tolist()\n",
    "    print('user_ids : {}'.format(len(user_ids)))\n",
    "    print('item_ids : {}'.format(len(item_ids)))\n",
    "    \n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(user_ids, bipartite=0)\n",
    "    B.add_nodes_from(item_ids, bipartite=1)\n",
    "    B.add_edges_from(edges)\n",
    "    print(nx.is_connected(B))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 Pixie: A System for Recommending 3+ Billion Items to 200+ Million Users in Real-Time 的 3.1 节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, alpha, N, root):\n",
    "    '''\n",
    "    G：图的结构，包含节点和边\n",
    "    alpha:决定漫步的长度\n",
    "    N:漫步的总的步数\n",
    "    root:开始的节点\n",
    "    '''\n",
    "    rank = {x:0 for x in G.nodes}\n",
    "    totSteps = 0\n",
    "    while totSteps <= N:\n",
    "        currPin = root\n",
    "        currSteps = np.random.randint(0, alpha)\n",
    "        for i in range(currSteps):\n",
    "            #随机选择与 root 相连的邻接点\n",
    "            nbs_1 = list(G.neighbors(currPin))\n",
    "            currBoard = nbs_1[np.random.randint(0, len(nbs_1))]\n",
    "            nbs_2 = list(G.neighbors(currBoard))\n",
    "            currPin = nbs_2[np.random.randint(0, len(nbs_2))]\n",
    "            nbs_3 = list(G.neighbors(currPin))\n",
    "            currBoard = nbs_3[np.random.randint(0, len(nbs_3))]\n",
    "            rank[currBoard] += 1\n",
    "            \n",
    "        totSteps += currSteps\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_ids : 943\n",
      "item_ids : 1650\n",
      "True\n",
      "user_ids : 459\n",
      "item_ids : 1410\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "B_train = preprocess(df_train)\n",
    "B_test = preprocess(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser = 'u1'\\nitem_ids = df_test[df_test.u_user_id == user].i_item_id.unique().tolist()\\n# 注意，每次传入的B_train都是新的，否则容易把 test 的边引入进来\\n# 例如， user1 和 user2 都对 test 的 item1 相连，如果测试 user1 时，添加进了\\n# （user2，item1）边，则在测试 user2 时，此边就变成已存在的，无法删除\\nB_train.add_nodes_from(item_ids, bipartite=1)\\nedges = df_test[(df_test.i_item_id.isin(item_ids) & (df_test.u_user_id != user))].edges.unique().tolist()\\nB_train.add_edges_from(edges)\\n\\nrank = random_walk(B_train, 20, 1000, 'u1')\\nmax([rank[key] for key in rank if 'u' not in key])\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "user = 'u1'\n",
    "item_ids = df_test[df_test.u_user_id == user].i_item_id.unique().tolist()\n",
    "# 注意，每次传入的B_train都是新的，否则容易把 test 的边引入进来\n",
    "# 例如， user1 和 user2 都对 test 的 item1 相连，如果测试 user1 时，添加进了\n",
    "# （user2，item1）边，则在测试 user2 时，此边就变成已存在的，无法删除\n",
    "B_train.add_nodes_from(item_ids, bipartite=1)\n",
    "edges = df_test[(df_test.i_item_id.isin(item_ids) & (df_test.u_user_id != user))].edges.unique().tolist()\n",
    "B_train.add_edges_from(edges)\n",
    "\n",
    "rank = random_walk(B_train, 20, 1000, 'u1')\n",
    "max([rank[key] for key in rank if 'u' not in key])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rank, user, top_k):\n",
    "    connect_item = [item_id for item_id in list(set(data[data['u_user_id'] == user]['i_item_id']))]\n",
    "    recommend_item = [(key, rank[key]) for key in rank if key not in connect_item and 'u' not in key]\n",
    "    top_k_item = sorted(recommend_item, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return top_k_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(test, user, top_k_item):\n",
    "    r_all = len(top_k_item)\n",
    "    if r_all != 0:\n",
    "        recom_list = [int(key[0][1:]) for key in top_k_item]\n",
    "        data = test[test.u_user_id==user]\n",
    "        r = len(data[(data.item_id.isin(recom_list))].item_id.unique())\n",
    "        p = r*1.0/r_all\n",
    "        return p\n",
    "    else:\n",
    "        return -2\n",
    "\n",
    "def recall(test, user ,top_k_item):\n",
    "    tu = test[test.u_user_id == user]['item_id'].nunique()\n",
    "    if tu != 0:\n",
    "        recom_list = [int(key[0][1:]) for key in top_k_item]\n",
    "        data = test[test.u_user_id==user]\n",
    "        r = len(data[(data.item_id.isin(recom_list))].item_id.unique())\n",
    "        rec = r*1.0/tu\n",
    "        return rec\n",
    "    else:\n",
    "        return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 91/943 [01:13<11:25,  1.24it/s]"
     ]
    }
   ],
   "source": [
    "# 获取 user 集合\n",
    "user_list = df_train.u_user_id.unique().tolist()\n",
    "rec = []\n",
    "pre = []\n",
    "G = deepcopy(B_train)\n",
    "begin_time = time.time()\n",
    "for user in tqdm(user_list):\n",
    "    item_ids = df_test[df_test.u_user_id == user].i_item_id.unique().tolist()\n",
    "    # 注意，每次传入的B_train都是新的，否则容易把 test 的边引入进来\n",
    "    # 例如， user1 和 user2 都对 test 的 item1 相连，如果测试 user1 时，添加进了\n",
    "    # （user2，item1）边，则在测试 user2 时，此边就变成已存在的，无法删除\n",
    "    B_train = deepcopy(G)\n",
    "    B_train.add_nodes_from(item_ids, bipartite=1)\n",
    "    edges = df_test[(df_test.i_item_id.isin(item_ids) & (df_test.u_user_id != user))].edges.unique().tolist()\n",
    "    B_train.add_edges_from(edges)\n",
    "    if(nx.is_connected(B_train)):\n",
    "        #rank = train(B_train, 0.6, user)\n",
    "        rank = random_walk(G, 20, 10000, user)\n",
    "        # top_k 的值取 train 里面相连的 1/4\n",
    "        top_k = int(len(list(B_train.neighbors(user)))/4)\n",
    "        top_k_item = predict(df_train, rank, user, top_k)\n",
    "        p = precision(df_test, user, top_k_item) \n",
    "        r = recall(df_test, user, top_k_item)\n",
    "        rec.append(r)\n",
    "        pre.append(p)\n",
    "    else:\n",
    "        rec.append(-1)\n",
    "        pre.append(-1)\n",
    "        \n",
    "        \n",
    "end_time = time.time()\n",
    "print(\"用时 ： {}\".format(end_time-begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'u_user_id':user_list, 'pre':pre, 'rec':rec})\n",
    "result.to_csv(\"result_random_walk.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['pre','rec']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从绘图的结果来看，id 靠前的用户，精确率一般大于召回率。这是由于我们推荐的TOP K中，K值过小（一般是正常的1/4），如果提高 K 值，则会提高召回率，但是会降低精确率。\n",
    "- 对比 day_3 的数据发现，整体的精确率和召回率比 PersonalRank 低，分析原因在于随机游走不确定性变大导致。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
